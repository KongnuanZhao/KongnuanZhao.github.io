title: GPU并行计算与CUDA编程01 
date: 2017-02-19 21:26:17
author: 赵空暖
tags:
- GPU
- CUDA
categories: GPU
---

##1 CPU与GPU的区别##

GPU 采用了数量众多的计算单元和超长流水线，但只有非常简单的控制逻辑并省去了Cache。而CPU不仅被Cache占据了大量空间，而且还有复杂的控制逻辑和诸多优化电路，相比之下计算能力只是CPU很小的一部分。

CPU的发展：处理器越来越小，处理速度越来越快，处理核变多。
从芯片上说：
性能：低延时性（Latency）与吞吐量（Throughput）
低延时性 --- 在最短的时间内处理完尽可能多的数据。
吞吐量 --- 

CPU -- 最大化速度上的优化，处理的越快越好（芯片设计理念、模式、散热……）
GPU -- 最大化吞吐量，处理的越多越好

###CPU###
ALU：CPU有强大的ALU（算术运算单元），它可以在很少的时钟周期内完成算术计算。
* 现在的CPU

Cache:大的缓存也可以降低延时。保存很多的数据放在缓存里面，当需要访问的这些数据，只要在之前访问过的，如今直接在缓存里面取即可。
Control:复杂的逻辑控制单元
* 当程序含有多个分支的时候，它通过提供分支预测的能力来降低延时。
* 数据转发。

###GPU###
ALU,Cache:GPU的特点是有很多的ALU和很少的Cache.缓存的目的不是保存后面需要访问的数据，和CPU不同，而是为Thread提高服务的。
Control:控制单元可以把多个的访问合并成少的访问。

* GPU虽然有dram延时，却又非常多的ALU和非常多的thread.为了平衡内存延时的问题，我们可以充分利用多ALU的特性达到一个非常大吞吐量的效果。尽可能多的分配多的Threads.通常GPU ALU会有非常重的pipeline。
* CPU擅长逻辑控制，串行的运算。和通用类型数据运算不同，GPU擅长的是大规模并发计算，这也正是密码破译等所需要的。所以GPU除了图像处理，也越来越多的参与到计算当中来。

##2 GPU并行计算的原理与意义##
什么类型的程序适合在GPU上运行？
1.计算密集型的程序。
2.易于并行的程序。GPU是一种SIMD（Single Instruction Multiple Data）架构。

##3 CUDA硬件环境与体系结构##
常见的显卡型号与性能，显卡的选择与显存需求估计

##4 本地机器的环境搭建步骤##

待补充..